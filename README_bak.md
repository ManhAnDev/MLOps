# ğŸ¯ ML Model Monitoring System

**This project is for demonstration purposes.**
A production-ready machine learning monitoring system using MLFlow, Prometheus, Grafana and Evidently for real-time model observability and performance tracking.

---

## ğŸ“‹ Table of Contents

- [Overview](#-overview)
- [Architecture](#-architecture)
- [Features](#-features)
- [Prerequisites](#-prerequisites)
- [Quick Start](#-quick-start)
- [Configuration](#-configuration)
- [Training Models](#-training-models)
- [Monitoring & Dashboards](#-monitoring--dashboards)
- [Evidently & Drift Monitoring](#-evidently--drift-monitoring)
- [Simulations & Load Testing](#-simulations--load-testing)
- [API Documentation](#-api-documentation)
- [Troubleshooting](#-troubleshooting)
- [Project Structure](#-project-structure)

---

## ğŸ¯ Overview

This project demonstrates a complete MLOps pipeline with real-time monitoring for production machine learning models. It includes:

- **Model Training & Registry**: Train models and manage versions with MLFlow
- **Model Serving**: FastAPI-based REST API for model predictions
- **Metrics Collection**: Prometheus for scraping model, API, and drift metrics
- **Visualization**: Grafana dashboards for real-time monitoring and drift analysis
- **Drift & Data Quality Monitoring**: Evidently service for distribution drift detection and reports
- **Storage**: MinIO (S3-compatible) for model artifacts
- **Database**: PostgreSQL for MLFlow backend store

**Use Cases:**
- Monitor model performance in production
- Track prediction latency and throughput
- Detect data drift and model degradation
- Compare model versions and A/B testing
- Alert on anomalies and performance issues

---

## ğŸ— Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          MONITORING STACK                           â”‚
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚  â”‚ Grafana  â”‚â”€â”€â”€â”€â”€â–¶â”‚Prometheusâ”‚â—€â”€â”€â”€â”€â”€â”‚ FastAPI  â”‚                  â”‚
â”‚  â”‚  :3000   â”‚      â”‚  :9090   â”‚      â”‚  :8000   â”‚                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚       â–²                     â–²             â”‚                         â”‚
â”‚       â”‚                     â”‚             â”‚                         â”‚
â”‚       â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”      â”‚                         â”‚
â”‚       â”‚            â”‚  Evidently    â”‚â—€â”€â”€â”€â”€â”€â”˜  (prediction capture)   â”‚
â”‚       â”‚            â”‚  :8001        â”‚  exposes drift/data-quality    â”‚
â”‚       â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€-â”˜  metrics to Prometheus         â”‚
â”‚       â”‚                                    â”‚                        â”‚
â”‚       â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚                        â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  MLFlow  â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                    â”‚  :5000   â”‚                                     â”‚
â”‚                    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                                     â”‚
â”‚                         â”‚                                           â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                â”‚
â”‚              â”‚                     â”‚                                â”‚
â”‚         â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”                            â”‚
â”‚         â”‚PostgreSQLâ”‚         â”‚  MinIO  â”‚                            â”‚
â”‚         â”‚  :5432   â”‚         â”‚  :9000  â”‚                            â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Components

| Service | Port | Description |
|---------|------|-------------|
| **MLFlow** | 5000 | Model registry and experiment tracking |
| **FastAPI** | 8000 | Model serving API with Prometheus metrics |
| **Evidently** | 8001 | Data drift & data-quality monitoring service (Prometheus + HTML reports) |
| **Prometheus** | 9090 | Metrics collection and storage |
| **Grafana** | 3000 | Visualization and dashboards (API + drift) |
| **MinIO** | 9000 | S3-compatible object storage for artifacts |
| **MinIO Console** | 9001 | MinIO web interface |
| **PostgreSQL** | 5432 | MLFlow backend database |

---

## Features

### Model Monitoring
- Real-time prediction latency tracking (p50, p95, p99)
- Request throughput and error rate monitoring
- Model version tracking and comparison
- Prediction distribution analysis
- Feature drift detection (via Prometheus + Evidently)

### Metrics Collection
- API request metrics (count, latency, status codes)
- Model prediction metrics (count, latency, errors)
- Feature value distributions for drift detection
- Model load time and version information
- Custom business metrics
- Drift and data-quality metrics from Evidently (drift score, drifted features, missing values)

### Visualization
- Pre-configured Grafana dashboards for API and model metrics
- Dedicated Grafana dashboard for Evidently drift monitoring
- Real-time metric updates
- Alert rules for anomaly and drift detection
- Historical trend analysis
- Multi-model comparison views

### Production Ready
- Docker Compose orchestration
- Health checks for all services
- Automatic MinIO bucket initialization
- Persistent data volumes
- Environment-based configuration

---

## Prerequisites

Before you begin, ensure you have the following installed:

- **Docker** (â‰¥ 20.10.0)
- **Docker Compose** (â‰¥ 2.0.0)
- **Python** (â‰¥ 3.10) - for model training
---

## Quick Start

### Repository

```bash
unzip ml-monitoring.zip
cd ml-monitoring
```

### Configure Environment

```bash
# Copy environment template
cp .env.example .env

# Edit .env if needed (optional for local development)
nano .env
```

**Default Configuration:**
- User: `mlops` (used for container naming)
- All passwords: use default for development

###  Start Infrastructure Services

Start all core infrastructure services (PostgreSQL, MinIO, MLFlow, Prometheus, Grafana):

```bash
docker-compose up -d postgres minio minio-init mlflow prometheus grafana
```

**Wait for services to be healthy**:

```bash
# Check service status
docker-compose ps

# All services should show "healthy" or "Up"
```

### ï¸Train and Register Model

**âš ï¸ IMPORTANT**: The API requires a trained model in MLFlow Registry before it can start!

```bash
# Install Python dependencies
pip install -r scripts/requirements.txt

# Train and register model
python scripts/training.py
```

**Expected Output:**
```
 MLFlow Tracking URI: http://localhost:5000
  Loading wine dataset...
  Training samples: 142
  Test samples: 36
  Training model...
 Model Performance:
   Accuracy:  0.9722
   F1 Score:  0.9722
   Precision: 0.9750
   Recall:    0.9722
 Model promoted to Production!
   Model: wine_quality_model
   Version: 1
   Stage: Production
```

**What this script does:**
1. Trains a RandomForest classifier on wine dataset
2. Logs model, parameters, and metrics to MLFlow
3. Registers model in MLFlow Model Registry
4. Promotes model to **Production** stage
5. Stores artifacts in MinIO bucket

### Start Model Serving API

Now that the model is registered, start the API:

```bash
docker-compose up -d api
```

**Verify API is running:**

```bash
# Check health
curl http://localhost:8000/health

# Expected output:
# {
#   "status": "healthy",
#   "model_loaded": true,
#   "model_name": "wine_quality_model",
#   "model_version": "1",
#   "uptime_seconds": 12.34
# }
```

### Start Evidently Drift Service (Optional but Recommended)

Evidently provides drift reports and additional Prometheus metrics:

```bash
docker-compose up -d evidently
```

**Verify Evidently is running:**

```bash
curl http://localhost:8001/health
```

You should see a JSON response with `status: "healthy"`.

### Generate Test Metrics (API & Drift)

Run the helper scripts to generate traffic and metrics:

```bash
# Basic API metrics & Prometheus/Grafana demo
chmod +x test_metrics.sh
./test_metrics.sh

# (Optional) More advanced drift simulations
cd simulations
pip install -r requirements.txt
./quick_test.sh         # small smoke test
python run_simulation.py -n 200 -s moderate_drift --analyze
cd ..
```

These scripts will:
- Send health and prediction requests to the API
- Generate Prometheus metrics for API and model
- Optionally send data to Evidently and trigger drift analysis
- Make it easy to visualize everything in Grafana

### Access Dashboards & UIs

| Service | URL | Credentials |
|---------|-----|-------------|
| **Grafana (API + Drift)** | http://localhost:3000 | admin / admin |
| **MLFlow** | http://localhost:5000 | - |
| **Prometheus** | http://localhost:9090 | - |
| **MinIO Console** | http://localhost:9001 | minio / minio123 |
| **Evidently API & Reports** | http://localhost:8001 | - (see `/docs`, `/reports`) |
| **API Docs** | http://localhost:8000/docs | - |

---

## Configuration

### Environment Variables

All configuration is managed through the `.env` file:

```bash
# User Configuration
USER=dongnd                    # Your username (for container naming)

# MLFlow Configuration
MLFLOW_PORT=5000              # MLFlow server port
MODEL_NAME=wine_quality_model # Model name in registry
MODEL_STAGE=Production        # Model stage to serve

# MinIO Configuration
MINIO_ROOT_USER=minio
MINIO_ROOT_PASSWORD=minio123 
MINIO_BUCKET_NAME=mlflow-artifacts

# Grafana Configuration
GRAFANA_ADMIN_USER=admin
GRAFANA_ADMIN_PASSWORD=admin

# See .env.example for all options
```

### Grafana Datasource

The Prometheus datasource is automatically provisioned with:
- **UID**: `prometheus-datasource` (stable reference)
- **URL**: `http://prometheus:9090`
- **Query Timeout**: 60s
- **HTTP Method**: POST (faster queries)
- **Incremental Querying**: Enabled

---

## Training Models

### Using the Training Script

The included training script (`scripts/training.py`) trains a RandomForest model on the wine dataset:

```bash
# Basic usage
python scripts/training.py
```

### Training Your Own Models

To train your own models:

1. **Create a training script** following this pattern:

```python
import mlflow
import mlflow.sklearn
import os

# Configure MLFlow
mlflow.set_tracking_uri('http://localhost:5000')
os.environ['MLFLOW_S3_ENDPOINT_URL'] = 'http://localhost:9000'
os.environ['AWS_ACCESS_KEY_ID'] = 'minio'
os.environ['AWS_SECRET_ACCESS_KEY'] = 'minio123'

# Train your model
with mlflow.start_run(run_name="my_model_v1"):
    # ... train model ...
    
    # Log model
    mlflow.sklearn.log_model(
        model,
        artifact_path="model",
        registered_model_name="my_model",
        signature=mlflow.models.infer_signature(X_train, predictions)
    )
    
    run_id = mlflow.active_run().info.run_id

# Promote to Production
client = mlflow.tracking.MlflowClient()
model_versions = client.get_latest_versions("my_model", stages=["None"])
if model_versions:
    client.transition_model_version_stage(
        name="my_model",
        version=model_versions[0].version,
        stage="Production"
    )
```

2. **Update environment variables** in `docker-compose.yml`:

```yaml
api:
  environment:
    - MODEL_NAME=my_model 
    - MODEL_STAGE=Production
```

3. **Restart the API**:

```bash
docker-compose restart api
```

### Model Requirements

Your model must:
- Be registered in MLFlow Model Registry
- Have a version promoted to the specified stage (default: Production)
- Be compatible with `mlflow.pyfunc.load_model()`
- Accept numeric array input for predictions

---

## Monitoring & Dashboards

### Accessing Grafana

1. Open http://localhost:3000
2. Login: `admin` / `admin`
3. Navigate to **Dashboards** â†’ **ML Monitoring** (API/model metrics)
4. Navigate to **Dashboards** â†’ **Evidently - Data Drift Monitoring** (drift metrics)

### Available Metrics

The API exposes these Prometheus metrics at `http://localhost:8000/metrics`:

#### API Metrics
```promql
# Request count by method, endpoint, and status
api_requests_total{method="POST",endpoint="/predict",status="200"}

# Request latency histogram
api_request_latency_seconds{method="POST",endpoint="/predict"}
```

#### Model Metrics
```promql
# Prediction count by model and version
model_predictions_total{model_name="wine_quality_model",model_version="1"}

# Prediction latency histogram
model_prediction_latency_seconds{model_name="wine_quality_model"}

# Prediction value distribution (for drift detection)
model_prediction_value{model_name="wine_quality_model"}

# Prediction errors by type
model_prediction_errors_total{model_name="wine_quality_model",error_type="..."}
```

#### System Metrics
```promql
# Current model version
model_version_info{model_name="wine_quality_model",version="1"}

# Model load time
model_load_time_seconds{model_name="wine_quality_model"}
```

### Example Queries

```promql
# Requests per second
rate(api_requests_total[5m])

# 95th percentile latency
histogram_quantile(0.95, rate(model_prediction_latency_seconds_bucket[5m]))

# Error rate
rate(model_prediction_errors_total[5m]) / rate(model_predictions_total[5m])

# Average prediction value (drift detection)
rate(model_prediction_value_sum[5m]) / rate(model_prediction_value_count[5m])
```

---

## Evidently & Drift Monitoring

Evidently runs as a separate service (port **8001**) and provides:

- **REST API** for capturing prediction data and triggering analysis
- **HTML reports** for detailed drift and data-quality inspection
- **Prometheus metrics** used by the Grafana drift dashboard

### Key Endpoints

- `GET /health` â€“ service health and summary
- `POST /capture` â€“ capture a single prediction (features + prediction)
- `POST /capture/batch` â€“ capture a batch of predictions
- `POST /analyze` â€“ run drift analysis on recent production data
- `GET /reports` â€“ list available HTML drift reports
- `GET /reports/{name}` â€“ view a specific report
- `GET /metrics` â€“ Prometheus metrics (e.g. `evidently_data_drift_detected`, `evidently_drift_score`)

### Typical Drift Monitoring Flow

1. The **API** serves predictions and exposes metrics at `/metrics`.
2. A **simulation script** (or your real app) sends traffic to `/predict`.
3. The simulator optionally **captures** each request/response to Evidently (`/capture`).
4. On a schedule (or manually), Evidently `/analyze` compares recent production data with reference data and:
   - Updates Prometheus metrics (drift status, scores, drifted features, missing values, etc.).
   - Generates an HTML drift report.
5. **Prometheus** scrapes Evidently, and **Grafana** dashboards visualize drift and data quality.

### Drift Dashboard in Grafana

- Dashboard UID: `evidently-drift`
- File: `config/grafana/dashboards/evidently-drift-monitoring.json`
- Shows:
  - Current drift status and drifted-features count
  - Drift score over time
  - Feature-level drift matrix
  - Analysis latency and rate
  - Missing-values ratio per feature

### Alerts

Prometheus alert rules for Evidently are defined in:

- `config/prometheus/evidently_alerts.yml`

Examples:

- `DataDriftDetected` â€“ drift detected for â‰¥ 5 minutes
- `MultipleDriftedFeatures` â€“ 3+ features drifting
- `HighDriftScore` â€“ drift score > 0.5
- `HighMissingValues` â€“ missing-values ratio > 20%
- `SlowDriftAnalysis` â€“ analysis taking too long

These alerts can be wired to Alertmanager / Slack / email as needed.

---

## Simulations & Load Testing

To generate realistic traffic and drift scenarios, use the tools in the `simulations/` directory.

### Installation

```bash
cd simulations
pip install -r requirements.txt
```

### Quick Test

```bash
cd simulations
./quick_test.sh       # 20 quick requests to validate everything end-to-end
cd ..
```

### CLI Usage

```bash
cd simulations

# 100 normal requests at 2 req/s
python run_simulation.py -n 100 -s normal

# 200 requests with moderate drift + run Evidently analysis
python run_simulation.py -n 200 -s moderate_drift --analyze

# Burst traffic pattern
python run_simulation.py -p burst -s normal

# Gradual traffic increase
python run_simulation.py -p gradual -s normal
```

### Preâ€‘configured Scenarios

```bash
cd simulations

# Run a specific scenario
python scenarios.py 1  # Normal day traffic
python scenarios.py 2  # Gradual drift
python scenarios.py 3  # Sudden distribution shift
python scenarios.py 6  # Stress test

# Run all scenarios sequentially (demo)
python scenarios.py
```

These simulations:

- Hit the `/predict` endpoint on the API.
- Optionally **capture** each prediction to Evidently.
- Automatically **feed** metrics and drift signals into Prometheus & Grafana.

---

## API Documentation

### Endpoints

#### `GET /`
Root endpoint with API information.

#### `GET /health`
Health check endpoint.

**Response:**
```json
{
  "status": "healthy",
  "model_loaded": true,
  "model_name": "wine_quality_model",
  "model_version": "1",
  "uptime_seconds": 123.45
}
```

#### `POST /predict`
Make predictions with the loaded model.

**Request:**
```json
{
  "features": [13.64, 3.1, 2.56, 15.2, 116.0, 2.7, 3.03, 0.17, 1.66, 5.1, 0.96, 3.36, 845.0],
  "feature_names": ["fixed_acidity", "volatile_acidity", ...] // optional
}
```

**Response:**
```json
{
  "prediction": 1.0,
  "model_name": "wine_quality_model",
  "model_version": "1",
  "timestamp": "2025-11-19T12:00:00",
  "latency_ms": 15.23
}
```

#### `GET /model/info`
Get loaded model information.

#### `POST /model/reload`
Reload model from registry.

#### `GET /metrics`
Prometheus metrics endpoint.

### Interactive API Docs

Access Swagger UI at: http://localhost:8000/docs

---

## Troubleshooting

### Common Issues

#### 1. API fails to start: "Model not loaded"

**Problem**: No model registered in MLFlow or wrong model name/stage.

**Solution:**
```bash
# Check if model exists
curl http://localhost:5000/api/2.0/mlflow/registered-models/get?name=wine_quality_model

# Train and register model
python scripts/training.py

# Restart API
docker-compose restart api
```

#### 2. MLFlow healthcheck failing

**Problem**: Port mismatch or MLFlow not ready.

**Solution:**
```bash
# Check MLFlow logs
docker-compose logs mlflow

# Verify port (should be 5000)
docker-compose ps mlflow

# Restart if needed
docker-compose restart mlflow
```

#### 3. MinIO bucket not created

**Problem**: minio-init service failed.

**Solution:**
```bash
# Check init logs
docker-compose logs minio-init

# Manual bucket creation
docker-compose exec minio mc alias set myminio http://localhost:9000 minio minio123
docker-compose exec minio mc mb myminio/mlflow-artifacts --ignore-existing
```

#### 4. Grafana datasource not working

**Problem**: Prometheus not accessible or wrong configuration.

**Solution:**
```bash
# Test Prometheus
curl http://localhost:9090/-/healthy

# Check Grafana datasource
# Go to: http://localhost:3000/datasources
# Click Prometheus â†’ Test

# Verify configuration in:
cat config/grafana/provisioning/datasources/prometheus.yml
```

### Service Health Checks

```bash
# Check all services
docker-compose ps

# Check specific service logs
docker-compose logs -f mlflow
docker-compose logs -f api
docker-compose logs -f prometheus
docker-compose logs -f grafana

# Test endpoints
curl http://localhost:5000/health    # MLFlow
curl http://localhost:8000/health    # API
curl http://localhost:9090/-/healthy # Prometheus
curl http://localhost:3000/api/health # Grafana
```

### Reset Everything

```bash
# Stop all services
docker-compose down

# Remove volumes (ï¸deletes all data!)
docker-compose down -v

# Rebuild and start fresh
docker-compose build
docker-compose up -d postgres minio minio-init mlflow prometheus grafana

# Train model again
python scripts/training.py

# Start API
docker-compose up -d api
```

---

## Project Structure

```
ml-monitoring/
â”œâ”€â”€ api/                          # FastAPI model serving
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ main.py                   # API application with metrics
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ mlflow/                       # MLFlow server
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ config/                       # Configuration files
â”‚   â”œâ”€â”€ prometheus.yml            # Prometheus scrape config
â”‚   â””â”€â”€ grafana/
â”‚       â”œâ”€â”€ provisioning/
â”‚       â”‚   â”œâ”€â”€ datasources/      # Grafana datasources
â”‚       â”‚   â”‚   â””â”€â”€ prometheus.yml
â”‚       â”‚   â””â”€â”€ dashboards/       # Dashboard provisioning
â”‚       â”‚       â””â”€â”€ dashboards.yml
â”‚       â”œâ”€â”€ dashboards/           # Dashboard JSON files
â”‚       â”‚   â””â”€â”€ ml-monitoring.json
â”‚       â””â”€â”€ alerts.yml            # Alert rules
â”œâ”€â”€ scripts/                      # Training and utility scripts
â”‚   â”œâ”€â”€ training.py               # Model training script
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ docker-compose.yml            # Main orchestration file
â”œâ”€â”€ .env.example                  # Environment template
â”œâ”€â”€ .env                          # Active environment config
â””â”€â”€ README.md                     # This file
```

---

## ğŸ“„ License

This project is provided as-is for demonstration purposes.